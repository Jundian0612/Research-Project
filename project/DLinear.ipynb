{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3856f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "#from darts import TimeSeries\n",
    "#from darts.models import DLinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d71bd14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder found: nc4\n",
      "Found 548 files.\n",
      "First 5 files: ['nc4/1980-01.nc4', 'nc4/1980-02.nc4', 'nc4/1980-03.nc4', 'nc4/1980-04.nc4', 'nc4/1980-05.nc4']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to open nc4/1980-01.nc4 with netcdf4 and h5netcdf.\ne1: unrecognized engine netcdf4 must be one of: ['scipy', 'store']\ne2: unrecognized engine h5netcdf must be one of: ['scipy', 'store']\n請確認這個環境有安裝 netCDF4 或 h5netcdf。",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnetcdf4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e1:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 改試 h5netcdf\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/geospatial-neural-adapter/lib/python3.10/site-packages/xarray/backends/api.py:559\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 559\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    562\u001b[0m     decode_cf,\n\u001b[1;32m    563\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/geospatial-neural-adapter/lib/python3.10/site-packages/xarray/backends/plugins.py:205\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m engines:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(engines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m     )\n\u001b[1;32m    208\u001b[0m backend \u001b[38;5;241m=\u001b[39m engines[engine]\n",
      "\u001b[0;31mValueError\u001b[0m: unrecognized engine netcdf4 must be one of: ['scipy', 'store']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mh5netcdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e2:\n",
      "File \u001b[0;32m~/miniconda3/envs/geospatial-neural-adapter/lib/python3.10/site-packages/xarray/backends/api.py:559\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 559\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    562\u001b[0m     decode_cf,\n\u001b[1;32m    563\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/geospatial-neural-adapter/lib/python3.10/site-packages/xarray/backends/plugins.py:205\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m engines:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(engines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m     )\n\u001b[1;32m    208\u001b[0m backend \u001b[38;5;241m=\u001b[39m engines[engine]\n",
      "\u001b[0;31mValueError\u001b[0m: unrecognized engine h5netcdf must be one of: ['scipy', 'store']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst 5 files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, file_list[:\u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 3. 用第一個檔案確認經緯度與變數存在\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m sample_data:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sample_data:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mopen_dataset(file_path, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5netcdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e2:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to open \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with netcdf4 and h5netcdf.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m請確認這個環境有安裝 netCDF4 或 h5netcdf。\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to open nc4/1980-01.nc4 with netcdf4 and h5netcdf.\ne1: unrecognized engine netcdf4 must be one of: ['scipy', 'store']\ne2: unrecognized engine h5netcdf must be one of: ['scipy', 'store']\n請確認這個環境有安裝 netCDF4 或 h5netcdf。"
     ]
    }
   ],
   "source": [
    "def check_data_folder(folder: str) -> bool:\n",
    "    return os.path.exists(folder) and os.path.isdir(folder)\n",
    "\n",
    "def load_data(file_path: str) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Load data from a NetCDF file, trying netcdf4 then h5netcdf.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    # 優先 netcdf4\n",
    "    try:\n",
    "        return xr.open_dataset(file_path, engine=\"netcdf4\")\n",
    "    except Exception as e1:\n",
    "        # 改試 h5netcdf\n",
    "        try:\n",
    "            return xr.open_dataset(file_path, engine=\"h5netcdf\")\n",
    "        except Exception as e2:\n",
    "            raise RuntimeError(\n",
    "                f\"Failed to open {file_path} with netcdf4 and h5netcdf.\\n\"\n",
    "                f\"e1: {e1}\\n\"\n",
    "                f\"e2: {e2}\\n\"\n",
    "                \"請確認這個環境有安裝 netCDF4 或 h5netcdf。\"\n",
    "            )\n",
    "\n",
    "# ================= main program =================\n",
    "\n",
    "data_folder = \"nc4\"\n",
    "var_name = \"TLML\"  # 目標變數名稱（請確認檔內真的叫這個）\n",
    "\n",
    "# 1. 檢查資料夾\n",
    "if not check_data_folder(data_folder):\n",
    "    raise FileNotFoundError(f\"Data folder not found: {data_folder}\")\n",
    "print(f\"Data folder found: {data_folder}\")\n",
    "\n",
    "# 2. 找出所有像 1980-01.nc4 的檔案\n",
    "pattern = os.path.join(data_folder, \"*.nc4\")\n",
    "file_list = sorted(glob.glob(pattern))\n",
    "\n",
    "if len(file_list) == 0:\n",
    "    raise FileNotFoundError(f\"No nc4 files found with pattern: {pattern}\")\n",
    "\n",
    "print(f\"Found {len(file_list)} files.\")\n",
    "print(\"First 5 files:\", file_list[:5])\n",
    "\n",
    "# 3. 用第一個檔案確認經緯度與變數存在\n",
    "with load_data(file_list[0]) as sample_data:\n",
    "    if var_name not in sample_data:\n",
    "        raise KeyError(f\"Variable '{var_name}' not found in file: {file_list[0]}\")\n",
    "    lat = sample_data[\"lat\"].values\n",
    "    lon = sample_data[\"lon\"].values\n",
    "\n",
    "nlat = lat.shape[0]\n",
    "nlon = lon.shape[0]\n",
    "print(f\"Lat: {nlat}, Lon: {nlon}\")\n",
    "\n",
    "# 4. 逐檔讀入，累積到 list\n",
    "data_list = []\n",
    "time_list = []\n",
    "\n",
    "for f in tqdm(file_list, desc=\"Combining\"):\n",
    "    with load_data(f) as ds:\n",
    "        da = ds[var_name]  # (time, lat, lon)\n",
    "\n",
    "        # 確保 lat/lon 一致（保險，可視情況註解）\n",
    "        if da.sizes[\"lat\"] != nlat or da.sizes[\"lon\"] != nlon:\n",
    "            raise ValueError(f\"Lat/Lon size mismatch in file: {f}\")\n",
    "\n",
    "        # 資料轉 float32，省記憶體\n",
    "        data_list.append(da.values.astype(np.float32))\n",
    "\n",
    "        if \"time\" not in ds:\n",
    "            raise KeyError(f\"'time' coordinate not found in file: {f}\")\n",
    "\n",
    "        # decode_cf 確保時間是真正 datetime\n",
    "        t = xr.decode_cf(ds)[\"time\"].values\n",
    "        time_list.append(t.astype(\"datetime64[ns]\"))\n",
    "\n",
    "# 5. 串起來 → (ntot, lat, lon) & DatetimeIndex\n",
    "combined = np.concatenate(data_list, axis=0)   # (ntot, nlat, nlon)\n",
    "time_array = np.concatenate(time_list, axis=0) # (ntot,)\n",
    "\n",
    "if combined.shape[0] != time_array.shape[0]:\n",
    "    raise ValueError(\n",
    "        f\"time length ({time_array.shape[0]}) \"\n",
    "        f\"!= data length ({combined.shape[0]})\"\n",
    "    )\n",
    "\n",
    "# 依時間排序（通常已排序，這裡是保險）\n",
    "sort_idx = np.argsort(time_array)\n",
    "combined = combined[sort_idx]\n",
    "time_array = time_array[sort_idx]\n",
    "\n",
    "time_index = pd.to_datetime(time_array)\n",
    "\n",
    "print(f\"Combined data shape: {combined.shape}\")\n",
    "print(f\"Time index: {time_index[0]} -> {time_index[-1]} (len={len(time_index)})\")\n",
    "\n",
    "# 6. 攤平成 cell × time\n",
    "ntot, nlat, nlon = combined.shape\n",
    "ncell = nlat * nlon\n",
    "\n",
    "# (cell, time)\n",
    "y_all = combined.reshape(ntot, ncell).T\n",
    "\n",
    "# 建立每個 cell 的 (lon, lat)\n",
    "lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "gg = np.column_stack([lon_grid.ravel(), lat_grid.ravel()])  # (cell, 2)\n",
    "\n",
    "print(f\"y_all shape: {y_all.shape}  (cells x time)\")\n",
    "print(f\"gg shape: {gg.shape}        (cells x [lon, lat])\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
